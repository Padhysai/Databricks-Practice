{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f129d0a-a724-46f2-9d56-d5ea7c2ca792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "\n",
    "df = spark.read.csv(\"AB_NYC_2019.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df = df.dropna(subset=[\"price\", \"number_of_reviews\"])\n",
    "\n",
    "df_filtered = df.filter((col(\"price\") > 0) & (col(\"price\") < 500))\n",
    "\n",
    "avg_price_per_neighborhood = df_filtered.groupBy(\"neighbourhood\").agg(avg(\"price\").alias(\"avg_price\"))\n",
    "\n",
    "avg_price_per_neighborhood.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91f7cf3d-b2e0-421e-b765-a89df3762589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "\n",
    "def load_data(spark, file_path):\n",
    "    return spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "def clean_data(df):\n",
    "    return df.dropna(subset=[\"price\", \"number_of_reviews\"])\n",
    "\n",
    "def filter_data(df, min_price, max_price):\n",
    "    return df.filter((col(\"price\") > min_price) & (col(\"price\") < max_price))\n",
    "\n",
    "def calculate_avg_price_per_neighborhood(df):\n",
    "    return df.groupBy(\"neighbourhood\").agg(avg(\"price\").alias(\"avg_price\"))\n",
    "\n",
    "def main():\n",
    "    df = load_data(spark, \"AB_NYC_2019.csv\")\n",
    "    df_cleaned = clean_data(df)\n",
    "    df_filtered = filter_data(df_cleaned, 0, 500)\n",
    "    avg_price_per_neighborhood = calculate_avg_price_per_neighborhood(df_filtered)\n",
    "    avg_price_per_neighborhood.show()\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Modularizing Pyspark code",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}